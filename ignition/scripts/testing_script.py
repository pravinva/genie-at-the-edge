"""
Testing and Validation Script for Mining Physics Simulation

This script provides comprehensive testing utilities for validating the physics simulation.
Run in Ignition Designer Script Console or as a standalone validation tool.

USAGE:
  Designer > Script Console > Paste this file > Execute

TESTS INCLUDED:
  1. Tag existence and structure validation
  2. Physics calculation accuracy tests
  3. Cycle state transition verification
  4. Performance benchmarking
  5. Data quality checks
  6. Fault injection validation

Author: Generated by Claude Code
Date: 2026-02-14
Version: 1.0
"""

import system.tag
import system.util
import random
from java.lang import Math, System

# ============================================
# CONFIGURATION
# ============================================

TAG_BASE_PATH = "[default]Mining/Equipment"
logger = system.util.getLogger("MiningSimulationTesting")

# Equipment IDs
HAUL_TRUCKS = ["HT_001", "HT_002", "HT_003", "HT_004", "HT_005"]
CRUSHERS = ["CR_001", "CR_002", "CR_003"]
CONVEYORS = ["CV_001", "CV_002"]

# ============================================
# TEST 1: TAG STRUCTURE VALIDATION
# ============================================

def test_tag_structure():
    """
    Verify all required tags exist and are accessible

    Returns:
        dict: Test results
    """
    logger.info("Running Test 1: Tag Structure Validation")

    results = {
        "test_name": "Tag Structure Validation",
        "passed": True,
        "errors": [],
        "warnings": [],
        "details": {}
    }

    # Expected tag structure for each equipment type
    haul_truck_tags = [
        "Location_Lat", "Location_Lon", "Speed_KPH", "Load_Tonnes",
        "Fuel_Level_Pct", "Engine_Temp_C", "Tire_Pressure_FL_PSI",
        "Tire_Pressure_FR_PSI", "Tire_Pressure_RL_PSI", "Tire_Pressure_RR_PSI",
        "Vibration_MM_S", "Operator_ID", "Cycle_State", "Cycle_Time_Sec",
        "Hours_Operated"
    ]

    crusher_tags = [
        "Status", "Throughput_TPH", "Vibration_MM_S", "Motor_Current_A",
        "Belt_Speed_M_S", "Chute_Level_Pct", "Runtime_Hours",
        "Feed_Rate_TPH", "Motor_Temp_C"
    ]

    conveyor_tags = [
        "Speed_M_S", "Load_Pct", "Motor_Temp_C", "Belt_Alignment_MM", "Status"
    ]

    # Test haul trucks
    for truck_id in HAUL_TRUCKS:
        for tag_name in haul_truck_tags:
            tag_path = "{}/{}/{}".format(TAG_BASE_PATH, truck_id, tag_name)
            try:
                value = system.tag.readBlocking([tag_path])[0]
                if not value.quality.isGood():
                    results["errors"].append("{}: Bad quality".format(tag_path))
                    results["passed"] = False
            except Exception as e:
                results["errors"].append("{}: {}".format(tag_path, str(e)))
                results["passed"] = False

    # Test crushers
    for crusher_id in CRUSHERS:
        for tag_name in crusher_tags:
            tag_path = "{}/{}/{}".format(TAG_BASE_PATH, crusher_id, tag_name)
            try:
                value = system.tag.readBlocking([tag_path])[0]
                if not value.quality.isGood():
                    results["errors"].append("{}: Bad quality".format(tag_path))
                    results["passed"] = False
            except Exception as e:
                results["errors"].append("{}: {}".format(tag_path, str(e)))
                results["passed"] = False

    # Test conveyors
    for conveyor_id in CONVEYORS:
        for tag_name in conveyor_tags:
            tag_path = "{}/{}/{}".format(TAG_BASE_PATH, conveyor_id, tag_name)
            try:
                value = system.tag.readBlocking([tag_path])[0]
                if not value.quality.isGood():
                    results["errors"].append("{}: Bad quality".format(tag_path))
                    results["passed"] = False
            except Exception as e:
                results["errors"].append("{}: {}".format(tag_path, str(e)))
                results["passed"] = False

    # Count tags
    expected_tags = len(HAUL_TRUCKS) * len(haul_truck_tags) + \
                    len(CRUSHERS) * len(crusher_tags) + \
                    len(CONVEYORS) * len(conveyor_tags)

    results["details"]["expected_tags"] = expected_tags
    results["details"]["errors_found"] = len(results["errors"])

    return results


# ============================================
# TEST 2: PHYSICS CALCULATIONS
# ============================================

def test_physics_calculations():
    """
    Verify physics calculations return values in expected ranges

    Returns:
        dict: Test results
    """
    logger.info("Running Test 2: Physics Calculations")

    results = {
        "test_name": "Physics Calculations",
        "passed": True,
        "errors": [],
        "warnings": [],
        "details": {}
    }

    # Test haul truck values
    for truck_id in HAUL_TRUCKS:
        base_path = "{}/{}/".format(TAG_BASE_PATH, truck_id)

        try:
            # Read key parameters
            tags = [
                base_path + "Speed_KPH",
                base_path + "Load_Tonnes",
                base_path + "Engine_Temp_C",
                base_path + "Fuel_Level_Pct",
                base_path + "Vibration_MM_S"
            ]

            values = system.tag.readBlocking(tags)

            speed = values[0].value
            load = values[1].value
            temp = values[2].value
            fuel = values[3].value
            vibration = values[4].value

            # Validate ranges
            if not (0 <= speed <= 70):
                results["errors"].append("{}: Speed {:.1f} km/h out of range [0-70]".format(
                    truck_id, speed))
                results["passed"] = False

            if not (0 <= load <= 260):
                results["errors"].append("{}: Load {:.1f} tonnes out of range [0-260]".format(
                    truck_id, load))
                results["passed"] = False

            if not (60 <= temp <= 120):
                results["errors"].append("{}: Engine temp {:.1f} C out of range [60-120]".format(
                    truck_id, temp))
                results["passed"] = False

            if not (0 <= fuel <= 100):
                results["errors"].append("{}: Fuel {:.1f}% out of range [0-100]".format(
                    truck_id, fuel))
                results["passed"] = False

            if not (0 <= vibration <= 25):
                results["errors"].append("{}: Vibration {:.1f} mm/s out of range [0-25]".format(
                    truck_id, vibration))
                results["passed"] = False

            # Check correlations
            if speed > 40 and load > 200:
                results["warnings"].append("{}: High speed ({:.1f} km/h) with high load ({:.1f} t) - unusual".format(
                    truck_id, speed, load))

        except Exception as e:
            results["errors"].append("{}: {}".format(truck_id, str(e)))
            results["passed"] = False

    # Test crusher values
    for crusher_id in CRUSHERS:
        base_path = "{}/{}/".format(TAG_BASE_PATH, crusher_id)

        try:
            tags = [
                base_path + "Throughput_TPH",
                base_path + "Vibration_MM_S",
                base_path + "Motor_Current_A",
                base_path + "Motor_Temp_C"
            ]

            values = system.tag.readBlocking(tags)

            throughput = values[0].value
            vibration = values[1].value
            current = values[2].value
            temp = values[3].value

            # Validate ranges
            if not (0 <= throughput <= 3500):
                results["errors"].append("{}: Throughput {:.0f} t/hr out of range [0-3500]".format(
                    crusher_id, throughput))
                results["passed"] = False

            if not (5 <= vibration <= 100):
                results["errors"].append("{}: Vibration {:.1f} mm/s out of range [5-100]".format(
                    crusher_id, vibration))
                results["passed"] = False

            if not (50 <= current <= 300):
                results["errors"].append("{}: Motor current {:.1f} A out of range [50-300]".format(
                    crusher_id, current))
                results["passed"] = False

            if not (50 <= temp <= 150):
                results["errors"].append("{}: Motor temp {:.1f} C out of range [50-150]".format(
                    crusher_id, temp))
                results["passed"] = False

            # Warning for high vibration (but not error - fault injection might be active)
            if vibration > 40:
                results["warnings"].append("{}: High vibration {:.1f} mm/s (fault injection active?)".format(
                    crusher_id, vibration))

        except Exception as e:
            results["errors"].append("{}: {}".format(crusher_id, str(e)))
            results["passed"] = False

    return results


# ============================================
# TEST 3: CYCLE STATE TRANSITIONS
# ============================================

def test_cycle_transitions(duration_seconds=30):
    """
    Monitor haul truck cycle state transitions over time

    Args:
        duration_seconds (int): How long to monitor (default 30 seconds)

    Returns:
        dict: Test results
    """
    logger.info("Running Test 3: Cycle State Transitions ({}s)".format(duration_seconds))

    results = {
        "test_name": "Cycle State Transitions",
        "passed": True,
        "errors": [],
        "warnings": [],
        "details": {}
    }

    # Monitor one truck (HT_001) for cycle progression
    truck_id = "HT_001"
    base_path = "{}/{}/".format(TAG_BASE_PATH, truck_id)

    # Record initial state
    tags = [
        base_path + "Cycle_Time_Sec",
        base_path + "Cycle_State",
        base_path + "Speed_KPH",
        base_path + "Load_Tonnes"
    ]

    initial_values = system.tag.readBlocking(tags)
    initial_cycle_time = initial_values[0].value
    initial_state = initial_values[1].value

    logger.info("Initial: Cycle={} sec, State={}".format(initial_cycle_time, initial_state))

    # Wait specified duration
    system.util.invokeLater(lambda: None, duration_seconds * 1000)

    # Read final state
    final_values = system.tag.readBlocking(tags)
    final_cycle_time = final_values[0].value
    final_state = final_values[1].value
    final_speed = final_values[2].value
    final_load = final_values[3].value

    logger.info("Final: Cycle={} sec, State={}, Speed={:.1f} km/h, Load={:.1f} t".format(
        final_cycle_time, final_state, final_speed, final_load))

    # Verify cycle time incremented
    time_delta = final_cycle_time - initial_cycle_time

    # Handle wrap-around
    if time_delta < 0:
        time_delta = (1380 - initial_cycle_time) + final_cycle_time

    expected_delta = duration_seconds
    tolerance = 5  # Allow ±5 seconds tolerance

    if abs(time_delta - expected_delta) > tolerance:
        results["errors"].append("Cycle time increment {:.0f}s != expected {:.0f}s (tolerance ±{}s)".format(
            time_delta, expected_delta, tolerance))
        results["passed"] = False

    # Verify state consistency
    # Check that speed/load match the cycle state
    state_speed_map = {
        "loading": (0, 5),      # Nearly stationary
        "dumping": (0, 5),      # Nearly stationary
        "hauling_loaded": (20, 35),  # Moderate speed
        "returning_empty": (40, 60)  # High speed
    }

    if final_state in state_speed_map:
        min_speed, max_speed = state_speed_map[final_state]
        if not (min_speed <= final_speed <= max_speed):
            results["errors"].append("State '{}' expects speed {}-{} km/h, got {:.1f} km/h".format(
                final_state, min_speed, max_speed, final_speed))
            results["passed"] = False

    # Check load consistency
    if final_state in ["hauling_loaded"]:
        if final_load < 200:
            results["warnings"].append("State '{}' expects high load, got {:.1f} tonnes".format(
                final_state, final_load))
    elif final_state in ["returning_empty"]:
        if final_load > 50:
            results["warnings"].append("State '{}' expects low load, got {:.1f} tonnes".format(
                final_state, final_load))

    results["details"]["initial_cycle_time"] = initial_cycle_time
    results["details"]["final_cycle_time"] = final_cycle_time
    results["details"]["time_delta"] = time_delta
    results["details"]["state_transition"] = "{} -> {}".format(initial_state, final_state)

    return results


# ============================================
# TEST 4: PERFORMANCE BENCHMARKING
# ============================================

def test_performance():
    """
    Measure tag read/write performance

    Returns:
        dict: Test results
    """
    logger.info("Running Test 4: Performance Benchmarking")

    results = {
        "test_name": "Performance Benchmarking",
        "passed": True,
        "errors": [],
        "warnings": [],
        "details": {}
    }

    # Test 1: Single tag read performance
    tag_path = "{}/HT_001/Speed_KPH".format(TAG_BASE_PATH)

    start_time = System.currentTimeMillis()
    for i in range(100):
        value = system.tag.readBlocking([tag_path])
    end_time = System.currentTimeMillis()

    single_read_time = (end_time - start_time) / 100.0
    results["details"]["single_tag_read_ms"] = single_read_time

    if single_read_time > 10:
        results["warnings"].append("Single tag read time {:.1f}ms > 10ms threshold".format(single_read_time))

    # Test 2: Batch read performance (15 tags - one truck)
    truck_tags = [
        "{}/HT_001/{}".format(TAG_BASE_PATH, tag) for tag in [
            "Speed_KPH", "Load_Tonnes", "Fuel_Level_Pct", "Engine_Temp_C",
            "Vibration_MM_S", "Location_Lat", "Location_Lon",
            "Tire_Pressure_FL_PSI", "Tire_Pressure_FR_PSI",
            "Tire_Pressure_RL_PSI", "Tire_Pressure_RR_PSI",
            "Cycle_Time_Sec", "Cycle_State", "Hours_Operated", "Operator_ID"
        ]
    ]

    start_time = System.currentTimeMillis()
    for i in range(10):
        values = system.tag.readBlocking(truck_tags)
    end_time = System.currentTimeMillis()

    batch_read_time = (end_time - start_time) / 10.0
    results["details"]["batch_15_tags_read_ms"] = batch_read_time

    if batch_read_time > 50:
        results["warnings"].append("Batch read time {:.1f}ms > 50ms threshold".format(batch_read_time))

    # Test 3: Write performance
    write_path = "{}/HT_001/Speed_KPH".format(TAG_BASE_PATH)

    start_time = System.currentTimeMillis()
    for i in range(50):
        system.tag.writeBlocking([write_path], [float(i)])
    end_time = System.currentTimeMillis()

    write_time = (end_time - start_time) / 50.0
    results["details"]["single_tag_write_ms"] = write_time

    if write_time > 15:
        results["warnings"].append("Single tag write time {:.1f}ms > 15ms threshold".format(write_time))

    # Estimate full simulation cycle time
    # 5 trucks × 15 tags = 75 tags
    # 3 crushers × 9 tags = 27 tags
    # 2 conveyors × 5 tags = 10 tags
    # Total: ~112 tag operations per second

    estimated_cycle_time = (batch_read_time / 15.0) * 112
    results["details"]["estimated_simulation_cycle_ms"] = estimated_cycle_time

    if estimated_cycle_time > 500:
        results["errors"].append("Estimated simulation cycle {:.0f}ms > 500ms - may not keep up with 1s interval".format(
            estimated_cycle_time))
        results["passed"] = False
    elif estimated_cycle_time > 200:
        results["warnings"].append("Estimated simulation cycle {:.0f}ms > 200ms - monitor performance".format(
            estimated_cycle_time))

    return results


# ============================================
# TEST 5: DATA QUALITY CHECKS
# ============================================

def test_data_quality(sample_duration_seconds=10):
    """
    Check for data quality issues (stuck values, null values, etc.)

    Args:
        sample_duration_seconds (int): Sampling duration

    Returns:
        dict: Test results
    """
    logger.info("Running Test 5: Data Quality Checks ({}s sampling)".format(sample_duration_seconds))

    results = {
        "test_name": "Data Quality Checks",
        "passed": True,
        "errors": [],
        "warnings": [],
        "details": {}
    }

    # Sample one truck over time
    truck_id = "HT_001"
    tag_path = "{}/{}/Speed_KPH".format(TAG_BASE_PATH, truck_id)

    samples = []
    sample_count = 5

    for i in range(sample_count):
        value = system.tag.readBlocking([tag_path])[0].value
        samples.append(value)

        if i < sample_count - 1:
            system.util.invokeLater(lambda: None, sample_duration_seconds * 1000 / sample_count)

    # Check for stuck values (all samples identical)
    if len(set(samples)) == 1:
        results["errors"].append("{}: Speed stuck at {:.1f} km/h across {} samples".format(
            truck_id, samples[0], sample_count))
        results["passed"] = False

    # Check for null values
    null_count = sum(1 for s in samples if s is None)
    if null_count > 0:
        results["errors"].append("{}: {} null values in {} samples".format(
            truck_id, null_count, sample_count))
        results["passed"] = False

    results["details"]["samples"] = samples
    results["details"]["unique_values"] = len(set(samples))
    results["details"]["null_count"] = null_count

    # Check crusher for unrealistic constant vibration (should vary)
    crusher_id = "CR_001"
    crusher_tag = "{}/{}/Vibration_MM_S".format(TAG_BASE_PATH, crusher_id)

    crusher_samples = []
    for i in range(sample_count):
        value = system.tag.readBlocking([crusher_tag])[0].value
        crusher_samples.append(value)

        if i < sample_count - 1:
            system.util.invokeLater(lambda: None, sample_duration_seconds * 1000 / sample_count)

    # Vibration should vary (not be perfectly constant)
    if len(set(crusher_samples)) == 1:
        results["warnings"].append("{}: Vibration constant at {:.1f} mm/s - needs realistic noise".format(
            crusher_id, crusher_samples[0]))

    return results


# ============================================
# TEST 6: FAULT INJECTION VALIDATION
# ============================================

def test_fault_injection():
    """
    Verify fault injection system for CR_002

    Returns:
        dict: Test results
    """
    logger.info("Running Test 6: Fault Injection Validation")

    results = {
        "test_name": "Fault Injection Validation",
        "passed": True,
        "errors": [],
        "warnings": [],
        "details": {}
    }

    # Check if fault state tags exist
    fault_tags = [
        "{}/CR_002/Fault_Enabled".format(TAG_BASE_PATH),
        "{}/CR_002/Fault_Elapsed_Hours".format(TAG_BASE_PATH),
        "{}/CR_002/Fault_Phase".format(TAG_BASE_PATH)
    ]

    try:
        values = system.tag.readBlocking(fault_tags)

        fault_enabled = values[0].value
        elapsed_hours = values[1].value
        fault_phase = values[2].value

        results["details"]["fault_enabled"] = fault_enabled
        results["details"]["elapsed_hours"] = elapsed_hours
        results["details"]["fault_phase"] = fault_phase

        if fault_enabled:
            results["warnings"].append("CR_002 fault injection is currently ACTIVE (phase: {})".format(fault_phase))

            # Verify vibration is elevated
            vibration_path = "{}/CR_002/Vibration_MM_S".format(TAG_BASE_PATH)
            vibration = system.tag.readBlocking([vibration_path])[0].value

            if fault_phase in ["warning", "critical"] and vibration < 35:
                results["errors"].append("CR_002 in {} phase but vibration only {:.1f} mm/s (expected >35)".format(
                    fault_phase, vibration))
                results["passed"] = False

            results["details"]["current_vibration"] = vibration
        else:
            results["details"]["message"] = "Fault injection not active - normal operation"

    except Exception as e:
        results["warnings"].append("Fault state tags not found: {}".format(str(e)))
        results["details"]["message"] = "Fault injection tags may not be created yet"

    return results


# ============================================
# MASTER TEST RUNNER
# ============================================

def run_all_tests():
    """
    Run all validation tests and produce summary report

    Returns:
        dict: Complete test results
    """
    logger.info("=" * 70)
    logger.info("MINING PHYSICS SIMULATION - VALIDATION TEST SUITE")
    logger.info("=" * 70)

    all_results = []

    # Run all tests
    tests = [
        test_tag_structure,
        test_physics_calculations,
        test_cycle_transitions,
        test_performance,
        test_data_quality,
        test_fault_injection
    ]

    for test_func in tests:
        try:
            result = test_func()
            all_results.append(result)
        except Exception as e:
            logger.error("Test {} failed with exception: {}".format(
                test_func.__name__, str(e)))
            all_results.append({
                "test_name": test_func.__name__,
                "passed": False,
                "errors": [str(e)],
                "warnings": [],
                "details": {}
            })

    # Generate summary
    logger.info("\n" + "=" * 70)
    logger.info("TEST SUMMARY")
    logger.info("=" * 70)

    passed_count = sum(1 for r in all_results if r["passed"])
    total_count = len(all_results)

    for result in all_results:
        status = "PASS" if result["passed"] else "FAIL"
        logger.info("[{}] {}".format(status, result["test_name"]))

        if result["errors"]:
            for error in result["errors"]:
                logger.info("  ERROR: {}".format(error))

        if result["warnings"]:
            for warning in result["warnings"]:
                logger.info("  WARNING: {}".format(warning))

    logger.info("\n" + "-" * 70)
    logger.info("RESULTS: {}/{} tests passed".format(passed_count, total_count))
    logger.info("=" * 70)

    return {
        "passed_count": passed_count,
        "total_count": total_count,
        "all_passed": passed_count == total_count,
        "results": all_results
    }


# ============================================
# QUICK DIAGNOSTICS
# ============================================

def quick_diagnostic():
    """
    Quick diagnostic check - useful for rapid troubleshooting

    Returns:
        str: Diagnostic summary
    """
    output = []
    output.append("QUICK DIAGNOSTIC - Mining Physics Simulation")
    output.append("=" * 60)

    # Check one truck
    truck_id = "HT_001"
    base_path = "{}/{}/".format(TAG_BASE_PATH, truck_id)

    try:
        tags = [
            base_path + "Cycle_Time_Sec",
            base_path + "Cycle_State",
            base_path + "Speed_KPH",
            base_path + "Load_Tonnes",
            base_path + "Engine_Temp_C"
        ]

        values = system.tag.readBlocking(tags)

        output.append("\n{}:".format(truck_id))
        output.append("  Cycle: {}s ({})".format(values[0].value, values[1].value))
        output.append("  Speed: {:.1f} km/h".format(values[2].value))
        output.append("  Load: {:.1f} tonnes".format(values[3].value))
        output.append("  Engine Temp: {:.1f} C".format(values[4].value))

    except Exception as e:
        output.append("  ERROR: {}".format(str(e)))

    # Check one crusher
    crusher_id = "CR_002"
    base_path = "{}/{}/".format(TAG_BASE_PATH, crusher_id)

    try:
        tags = [
            base_path + "Status",
            base_path + "Throughput_TPH",
            base_path + "Vibration_MM_S",
            base_path + "Motor_Temp_C"
        ]

        values = system.tag.readBlocking(tags)

        output.append("\n{}:".format(crusher_id))
        output.append("  Status: {}".format(values[0].value))
        output.append("  Throughput: {:.0f} t/hr".format(values[1].value))
        output.append("  Vibration: {:.1f} mm/s".format(values[2].value))
        output.append("  Motor Temp: {:.1f} C".format(values[3].value))

    except Exception as e:
        output.append("  ERROR: {}".format(str(e)))

    output.append("\n" + "=" * 60)

    result = "\n".join(output)
    logger.info(result)
    return result


# ============================================
# MAIN ENTRY POINT
# ============================================

if __name__ == '__main__' or True:
    # When executed in Script Console, run all tests
    logger.info("Mining Physics Simulation - Testing Script Loaded")
    logger.info("Available functions:")
    logger.info("  run_all_tests() - Run complete test suite")
    logger.info("  quick_diagnostic() - Quick status check")
    logger.info("  test_tag_structure() - Verify tag existence")
    logger.info("  test_physics_calculations() - Verify value ranges")
    logger.info("  test_performance() - Benchmark tag operations")
    logger.info("")
    logger.info("Execute: run_all_tests()")
